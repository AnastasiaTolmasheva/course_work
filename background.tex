\newpage
\section{Анализ предметной области}
\label{sec:Background}

%В разделе 1.1 представлен обзор предметной области проекта: что такое Open Journal System и какой может быть аккаунт. Далее рассмотрены аналогичные проекты, их описание расположено в разделе 1.2. Методы, которые могут использоваться для поиска фиктивных аккаунтов описаны в разделе 1.3. Обзор набора данных и принципы разметки расположены в разделе 1.4.

%\vspace{1.5em}
\subsection{Предметная область}
\label{subsec:Variants}

Open Journal System (OJS) -- это программное обеспечение, которое позволяет публиковать статьи и организовать рабочий процесс издательства. На ее основе разработаны многие порталы, работают институты, научные центры и журналы в разных странах мира (интерфейс OPS переведeн более чем на 30 языков). Платформа обладает модульной структурой и имеет возможность подключения плагинов. 

OJS может быть рассмотрена как электронная библиотека: программа обеспечивает доступ к контенту, поиск по нему (автора, ключевые слова, названия статей, год выпуска и так далее). 

Аккаунт в Open Journal Systems представляет собой учетную запись пользователя, которая позволяет взаимодействовать с системой в качестве автора, рецензента, читателя или редактора в научных журналах, использующих OJS для управления процессом публикации.

Авторы могут создавать и отправлять свои научные статьи на публикацию в журнал. Их аккаунт позволяет им отслеживать статус статей, вносить изменения в данные и взаимодействовать с рецензентами.

Рецензенты имеют доступ к предоставленным им статьям. Их аккаунт дает им возможность отправлять свои оценки, взаимодействовать с редакцией и следить за обновлениями в процессе рецензирования.

Читатели могут создавать свои учетные записи для отслеживания интересующих статей, подписываться на уведомления о новых публикациях, а также участвовать в дискуссиях в комментариях к статьям.

Редакторы имеют полный доступ к управлению процессом публикации в журнале. Это включает в себя принятие и отклонение статей, управление рецензиями, управление составом редакционной коллегии и другие аспекты редакционной работы.

Администраторы имеют права доступа ко всем функциям системы и могут управлять пользователями, настройками, архивами и другими аспектами системы.

Поля, доступные в учетной записи пользователя OJS, могут немного различаться в зависимости от версии системы и настроек конкретного журнала, но обычно они содержат следующие базовые характеристики: имя пользователя, пароль, электронная почта, имя, фамилия, страна, аффилиация (принадлежность пользователя к организации, университету или другому учреждению), язык, ссылка, телефон, почтовый адрес.

\vspace{1.5em}
\subsection{Обзор аналогичных проектов}
\label{subsec:Variants}

Нахождение фиктивных аккаунтов в Open Journal System является темой данной работы. Для выбора наилучшего подхода к решению задач и достижения цели были рассмотрены некоторые статьи на тему выявления <<фейков>> и их влияния на аккаунты реальных людей. Далее представлены исследования, которые были обозрены в ходе работы.

Авторы статьи~\cite{HassanAA23} раскрывают проблему поддельных страниц. Их количество растет вместе с увеличением числа активных пользователей. Фиктивные профили на сайтах социальных сетей создают ненастоящие новости и распространяют нежелательные материалы, содержащие спам-ссылки. В этой статье приводится контролируемый алгоритм машинного обучения, называемый машиной опорных векторов, который используется вместе с методом случайного леса. Эту концепцию можно применить для идентификации большого количества учетных записей, которые невозможно проверить вручную. Данная модель сравнивается с другими методами идентификации, и результаты показывают, что предложенный авторами алгоритм работает с большей точностью. 

Статья~\cite{ElyusufiEK19} посвящена выявлению поддельных профилей в социальных сетях. Для их обнаружения было предложено множество алгоритмов и методов, и авторы этой работы оценивают точность использования дерева решений и наивного Байесовского классификатора для разделения профилей пользователей на поддельные и подлинные.

В работе~\cite{UppadaMVHS22} исследователи используют модель, которая определяет подлинность новостных статей, публикуемых в Twitter, на основе подлинности и предвзятости пользователей, которые взаимодействуют с этими статьями. Предлагаемая модель включает в себя идею оценки соотношения подписчиков, возраст аккаунта и т.д. Для анализа изображений предлагается использовать нейронную сеть. Подход исследователей помогает обнаруживать поддельные изображения с точностью около 76\%.
    
В исследовании~\cite{GurajalaWHM15} проведен анализ 62 миллионов общедоступных профилей пользователей социальной сети Twitter, и разработана стратегия идентификации поддельных профилей. Используя алгоритм сопоставления шаблонов имен, анализ времени обновления записей и даты создания профилей, были выявлены фиктивные аккаунты. 

В статье~\cite{abs-2308-05353} описывается алгоритм для обнаружения поддельных учетных записей в социальной сети. Авторы работы собирают некоторые из первых аналитических данных о том, как новые (поддельные и реальные) аккаунты пытаются завести друзей, ориентируясь на их первые запросы о дружбе после регистрации в социальной сети. 

В работе~\cite{MohammadrezaeiS19} авторы представляют метод обнаружения, основанный на сходстве пользователей, с учетом их сетевых коммуникаций. На первом этапе измеряются такие параметры, как общие соседи, ребра графа общих соседей, косинус и коэффициент подобия Жаккарда~\cite{SantistebanT15}, которые вычисляются на основе матрицы смежности соответствующего графа социальной сети. На следующем шаге, чтобы уменьшить сложность данных, к каждой вычисленной матрице подобия применяется компонентный анализ для получения набора информативных признаков. Затем с помощью метода локтя выбирается набор высокоинформативных собственных векторов. Извлеченные функции используются для обучения алгоритма классификации. 

В статье~\cite{StolbovaGI21} представлено исследование поддельных аккаунтов в социальных сетях с использованием искусственной нейронной сети для их идентификации. Специально разработанное и внедренное приложение было использовано для выявления специфических особенностей поддельных аккаунтов и изучения принципов и причин их генерации. На основе изучения 500 реальных и 500 поддельных аккаунтов социальносй сети ВКонтакте был сделан ряд выводов об особенностях поддельных аккаунтов. Проведенное исследование позволило расширить список критериев идентификации поддельных аккаунтов набором шаблонов.

В статье~\cite{ChenW18} авторы нацеливаются на модель фиктивного аккаунта, который может не только автоматически публиковать сообщения или комментарии, но и рассылать рекламный спам или распространять ложную информацию. В этом исследовании был предложен метод обнаружения <<фейков>>, основанный на шаблоне активности пользователя, с использованием машинного обучения, чтобы предсказать, контролируется ли учетная запись поддельным пользователем.

Работа~\cite{HsuKJ19} представляет результаты экспериментальной визуализации более 200 000 постов из подтвержденных поддельных аккаунтов одной социальной сети. Авторы анализируют учетные записи пользователей, изучая их имена пользователей, описания или биографии, записи, их частоту и содержание. Исследователи обнаружили, что фиктивные аккаунты узнаваемы благодаря политическим и религиозным убеждениям.

Авторы статьи~\cite{FahmyAKE23} рассматривают влияние фиктивных аккаунтов на аккаунты людей. Цель работы -- представить новую модель распространения информации. Исследователи вводят два типа пользователей с разным уровнем <<зараженности>>: пользователи, <<инфицированные>> человеком, и пользователи, <<зараженные>> учетными записями ботов. Было измерено влияние поддельных аккаунтов на скорость распространения лжи среди записей людей. Результаты эксперимента показывали, что точность предложенной модели превосходит классическую при моделировании процесса распространения слухов. Был сделан вывод, что <<фейки>> ускоряют процесс распространения невподтвержденной информации, поскольку они воздействуют на многих людей за короткое время.

\vspace{1.5em}
\subsection{Обзор методов для поиска аномалий}
\label{subsec:Variants}

Поиск фиктивных аккаунтов можно рассмотреть как задачу обнаружения аномалий. Ниже представлены алгоритмы, которые можно использовать для этой решения проблемы.

\textbf{Изоляционный лес} (isolation forest)~\cite{LiuTZ08} представляет собой алгоритм обнаружения аномалий, который строит ансамбль изолирующих деревьев решений. 

\textit{Дерево изоляции}. Пусть $T$ -- узел дерева изоляции. $T$ может быть либо внешним узлом без дочерних узлов, либо внутренним узлом с одним тестом и ровно двумя дочерними узлами ($T_l$, $T_r$). Тест состоит из атрибута $q$ и значения разделения $p$, такого, что тест $q$ < $p$ разделяет точки данных на $T_l$ и $T_r$. 

Дана выборка данных $X = \{x_1, \ldots, x_n\}$ из $n$ экземпляров из $d$-мерного распределения. Для построения дерева изоляции мы рекурсивно делим $X$, случайно выбирая атрибут $q$ и значение разделения $p$, пока дерево не достигнет предельной высоты, либо $|X| = 1$, либо все данные в $X$ будут иметь одинаковые значения. Дерево изоляции -- это правильное бинарное дерево, где каждый узел в дереве имеет ровно ноль или два дочерних узла.

Одним из способов обнаружения аномалий с помощью дерева изоляции является сортировка точек данных по их длинам пути или оценкам аномалий. Аномалии -- это точки, которые занимают верхние позиции в списке. Длина пути $h(x)$ точки $x$ измеряется количеством ветвей, которые $x$ проходит в дереве изоляции от корневого узла до завершения обхода во внешнем узле.

Работа алгоритма изоляционного леса:

\begin{enumerate}[itemindent=2cm, leftmargin=0cm, labelsep=0.3cm, topsep=0cm, itemsep=0cm, parsep=0cm, label=\arabic*., after=\vspace{-0.1cm}, before=\vspace{-0.1cm}]
    \item Случайное разбиение. Дерево случайным образом выбирает атрибут и значение разделения данных. Это создает разделение, которое помогает выделить аномалии.
    \item Рекурсивная изоляция. Дерево повторяет процесс, разделяя данные на более мелкие группы. Цель состоит в том, чтобы изолировать аномалии от обычных данных.
    \item Идентификация аномалий. Аномалии идентифицируются как точки данных, для выделения которых требуется меньшее количество разбиений.
    \item Определение изолирующего пути. Определяется количество разбиений, необходимых для изоляции точки данных, служит мерой её аномальности.
    \item Ансамбль деревьев. Алгоритм создает несколько деревьев изоляции, независимых друг от друга, образующих ансамбль, который коллективно оценивает аномалии.
    \item Расчет оценки различий. Вычисляется среднее расстояние разделения между всеми деревьями для каждой точки данных, что дает оценку аномалии.
    \item Классификация. Используются предопределенные пороги для  нормальных и аномальных точек данных. Объекты с высокими оценками помечаются как аномалии.
\end{enumerate}

 
\textbf{Иерархическая кластеризация} (hierarchical clustering) -- это алгоритм группировки данных, который строит иерархию кластеров. Существует два основных подхода: агломеративный и дивизивный.

\textit{Агломеративная кластеризация}. Каждая точка рассматривается как отдельный кластер. На каждом шаге ближайшие кластеры объединяются в новый кластер (на основании расстояния между ними). Процесс повторяется до тех пор, пока все точки не объединятся в один кластер.
    
\textit{Дивизивная кластеризация}. Вся выборка рассматривается как один кластер. На каждом шаге один из кластеров разбивается на более мелкие кластеры (на основании мер несходства между подгруппами). Процесс повторяется до тех пор, пока каждая точка не станет отдельным кластером.

В данной работе рассматривалась агломеративная кластеризация~\cite{Banfield1993ModelbasedGA}. Ее алгоритм представлен на диаграмме последовательности (рисунок ~\ref{ris:actionshier}).

\begin{figure}[H]
    \center{\includegraphics[width=1\linewidth]{image}}
    \includegraphics[scale=0.47]{Курсовая работа/pic/Диаграмма деятельности_иерарх кластеризация.png}
    \caption{Диаграмма деятельности агломеративной кластеризации}
    \label{ris:actionshier}
\end{figure}

Для объединения кластеров необходимо вычситать расстояния между ними. В данной работе использовалось евклидово расстояние. Оно вычисляется как расстояние между центрами масс кластеров. Также нужно выбрать метод, каким образом данные будут объединяться кластеры. Наиболее распространенные методы: одиночной связи, полной связи, средней связи, Уорда.

Метод одиночной связи (single linkage): расстояние между кластерами равно минимальному расстоянию между точками из разных кластеров.
\[ d_{\min}(C_i, C_j) = \min_{x \in C_i, y \in C_j} \rho(x, y) \]

Метод полной связи (complete linkage): расстояние между кластерами равно максимальному расстоянию между точками из разных кластеров.
\[ d_{\max}(C_i, C_j) = \max_{x \in C_i, y \in C_j} \rho(x, y) \]

Метод средней связи (average linkage): расстояние между кластерами равно среднему расстоянию между всеми парами точек из разных кластеров.
\[ d_{\text{avg}}(C_i, C_j) = \frac{1}{n_i n_j} \sum_{x \in C_i} \sum_{y \in C_j} \rho(x, y) \]

\vspace{0.3cm}
Метод Уорда (Ward's linkage): расстояние между кластерами равно приросту суммы квадратов расстояний от точек до центроидов кластеров при объединении этих кластеров. Этот метод стремится минимизировать внутрикластерную дисперсию.
\[ d_{\text{ward}}(C_i, C_j) = \frac{n_i n_j}{n_i + n_j} \rho^2(\bar{x}_i, \bar{x}_j) \]


\textbf{DBSCAN} (Density-Based Spatial Clustering of Applications with Noise)~\cite{EsterKSX96} -- это алгоритм кластеризации, который определяет кластеры на основе плотности данных в пространстве. Он может обнаруживать группы произвольной формы и выделять точки, не принадлежащие ни одной из них (шум).
    
Для нахождения кластера DBSCAN начинает с произвольной точки $p$ и извлекает все точки, достижимые по плотности из $p$ относительно $\textit{Eps}$ и $\textit{MinPts}$. Если $p$ является ядром кластера, этот процесс создает кластер относительно $\textit{Eps}$ и $\textit{MinPts}$. Если $p$ является граничной точкой, и нет объектов, достижимых по плотности, и DBSCAN переходит к следующей записи в базе данных.

Для алгоритма DBSCAN необходимо указывать параметры $\textit{Eps}$ и $\textit{MinPts}$. Первый параметр определяет окрестности вокруг точек данных: если расстояние между двумя точками меньше или равно $\textit{Eps}$, то они считаются соседними. Второй представляет собой минимальное количество соседей (точек данных) в радиусе.

Работа алгоритма DBSCAN представлена на диаграмме последовательности (рисунок ~\ref{ris:actionsDBSCAN}).

\begin{figure}[H]
    \center{\includegraphics[width=1\linewidth]{image}}
    \includegraphics[scale=0.57]{Курсовая работа/pic/Диаграмма деятельности_DBSCAN.png}
    \caption{Диаграмма деятельности алгоритма DBSCAN}
    \label{ris:actionsDBSCAN}
\end{figure}

\vspace{1.5em}
\subsection{Обзор методов классификации}
\label{subsec:VariantsClass}
Поиск фиктивных аккаунтов можно также рассматривать как задачу классификации, некоторые методы представлены ниже.

\textbf{Дерево решений} (decision tree)~\cite{BreimanFOS84} -- это алгоритм машинного обучения для решения задач классификации.

Узлы дерева представляют собой проверки на признаки. Ветви -- переходы от одного узла к другому. Листья -- это узлы, представляющие собой окончательные решения по классификации, то есть они содержат подмножества, которые удовлетворяют всем парвилам ветви. Корневой узел -- верхний, начальный узел дерева решений, содержащий весь набор данных. Есть несколько критериев разбиения, наиболее популярные это индекс Джини и энтропия.

\textit{Индекс Джини} измеряет вероятность неправильной классификации при выборе случайного элемента из обучающей выборки. Он вычисляется по формуле:
$$
Gini = 1 - \displaystyle\sum_{i=1}^{n} p_i^2
$$

\vspace{0.3cm}
Индекс Джини может изменяться от 0 до $1 - \frac{1}{n}$. Он равен нулю, когда все объекты результирующего множества принаджелат одному классу, и $1 - \frac{1}{n}$, когда объекты равномерно распределены по всем классам. Наиболее желательная ситуация, когда индекс Джини минимальный.


\textit{Энтропия} измеряет неопределенность данных в узле. Она представляет количество информации, которое необходимо для описания состояния системы, и вычисляется по следующей формуле:
$$
Entropy = - \displaystyle\sum_{i=1}^{n} p_i \cdot \log_2 p_i
$$


Энтропия модет изменяться от 0 до $\log_2 n$. Она равна нулю, когда все объекты принадлежат одному классу (что является наиболее желательной ситуацией), и $\log_2 n$, когда объекты равномерно распределены по классам. 

Алгоритм дерева решений работает следующим образом:

\begin{enumerate}[itemindent=2cm, leftmargin=0cm, labelsep=0.3cm, topsep=0cm, itemsep=0cm, parsep=0cm, label=\arabic*., after=\vspace{-0.1cm}, before=\vspace{-0.1cm}]
    \item Выбор корневого узла. Весь набор данных используется как начальный узел.
    \item Выбор признака разбиения. Для каждого признака рассчитывается значение выбранного критерия. Тот признак, что дает наиболее желательный результат (в обоих случаях лучшее значение -- нуль) и выбирается для разбиения.
    \item Разбиение узла. Узел делится на подмножетсва, основанные на значении выбранного признака.
    \item Повторение для дочерних узлов. Для каждого последующего узла процесс повторяется рекурсивно, пока не будет достигнуто одно из условий остановки.
\end{enumerate}

Условия остановки алгоритма:

\begin{enumerate}[itemindent=2cm, leftmargin=0cm, labelsep=0.3cm, topsep=0cm, itemsep=0cm, parsep=0cm, label=\arabic*., after=\vspace{-0.1cm}, before=\vspace{-0.1cm}]
    \item Достигнута определенная глубина дерева.
    \item Узел не делится, если в его множество меньше определенного числа объектов.
    \item Следующее разбиение приведет к тому, что каждый лист не будет содержать заданного минимума объектов.
    \item Разбиение не выполняется, если оно не приводит к уменьшению <<нечистоты>> превышающему или равному заданному значению.
\end{enumerate}


\textbf{Случайный лес} (random forest)~\cite{Breiman01} -- это ансамблевый метод машинного обучения, который может использоваться для задач классификации. Он состоит из множества деревьев решений, каждое из которых обучается на случайной подвыборке исходных данных, что уменьшает корреляцию между их ошибками.

Алгоритм работы случайного леса:

\begin{enumerate}[itemindent=2cm, leftmargin=0cm, labelsep=0.3cm, topsep=0cm, itemsep=0cm, parsep=0cm, label=\arabic*., after=\vspace{-0.1cm}, before=\vspace{-0.1cm}]
    \item Для каждого дерева случайного леса формируется подвыборка данных с возвращением в исходный набор данных (некоторые объекты могут быть выбраны несколько раз, а некоторые не попасть в подвыборку).
    \item На вершине деревьев выбирается случайное подмножество признаков. Лучший из них используется для разбиения узла. Дерево строится до выполнения критерия остановки.
    \item Когда все деревья обучены, их предсказания комбинируются для получения итогового предсказания случайного леса: используется метод голосования большинства. 
\end{enumerate}


\vspace{1.5em}
\subsection{Метрики}
\label{subsec:Metrics}

Для оценки качества работы алгоритма будут использоваться метрики accuracy (аккуратность), precision (точность) и recall (полнота), F-measure (F-мера). Первая показывает долю верно классифицированных объектов, вторая -- долю объектов, которые модель классифицировала как положительные, и которые действительно являются положительными, третья -- долю объектов положительного класса, которые модель определила правильно, четвертая -- это комбинированная метрика, объединяющая точность и полноту в единственное число. Полнота демонстрирует способность алгоритма обнаруживать фиктивные аккаунты, а точность -- способность отличать их от других.

Данные метрики можно вычислить по следующим формулам:


$$
accuracy = \frac{TP+TN}{TP+TN+FP+FN}
$$

$$
precision = \frac{TP}{TP+FP}
$$

$$
recall = \frac{TP}{TP+FN}
$$

$$
F\text{-}measure = 2\cdot \frac{precision \cdot recall}{precision+recall}
$$

\vspace{1.5em}
Термины TP, TN, FP, FN используются в контексте матрицы ошибок (таблица ~\ref{tabular:tableMistakes}), которая является инструментом для оценки производительности моделей.

\begin{table}[H]
    \caption{Матрица ошибок}
    \vspace{1em}
    \small
    \begin{tabular}{|c|cc|}
        \hline
        & \text{Positive} & \text{Negative} \\
        \hline
        \text{True} & \text{True Positives} & \text{True Negatives} \\
        \text{False} & \text{False Positives} & \text{False Negatives} \\
    \hline
    \end{tabular}
    \label{tabular:tableMistakes}
\end{table}

TP (True Positives) -- количество верно предсказанных положительных примеров. В данной работе это будут те аккаунты, которые являются фиктивными, и алгоритм классифицировал их как аномальные.

TN (True Negatives) -- количество верно предсказанных отрицательных примеров. В данной работе это будут те аккаунты, которые являются реальными, и алгоритм не классифицировал их как аномальные.

FP (False Positives) -- количество ложно положительных примеров. В данной работе это будут те аккаунты, которые являются реальными, но алгоритм классифицировал их как аномальные.

FN (False Negatives) -- количество ложно отрицательных примеров. В данной работе это будут те аккаунты, которые являются фиктивными, но алгоритм не классифицировал их как аномальные.

\vspace{1.5em}
\subsection{Наборы данных}
\label{subsec:Dataset}

\textbf{Обучение}. Для обучения моделей был применен датасет с реальными данными аккаунов, который имеет следующие столбцы: user\_id, username, password, email, url, phone, mailing\_address, billing\_address, country, locales, date\_last\_email, date\_registered, date\_validated, date\_last\_login, must\_change\_password, auth\_id, auth\_str, disabled, disabled\_reason, inline\_help, gossip. 

Была произведена его разметка с добавлением колонки is\_fake, в которой 1 показывает, что аккаунт фиктивный, а 0 -- настоящий. 
Разметка происходила по следующим признакам:

\begin{enumerate}[itemindent=2cm, leftmargin=0cm, topsep=0cm, labelsep=0.3cm, itemsep=0cm, parsep=0cm, label=\arabic*., after=\vspace{-0.1cm}, before=\vspace{-0.1cm}]
    \item Проверка email на валидность (просмотр синтаксиса и возможности доставки на домен). Если почта не валидна, аккаунт считался фиктивным (например, аккаунт с email admin@cr6ptobrowser.site).
    \item Проверка работы ссылки, указанной в аккаунте. Если ссылка не работала, то аккаунт считался фиктивным.
    \item Проверка содержимого сайта, указанного в ссылке аккаунта. Если там находится что-либо, не связанное с научными публикациями, аккаунт считался фиктивным (например, аккаунт с ссылкой на казино).
    \item Просмотр ближайших строк по времени регистрации -- если имена пользователей, email или billing\_addres различаются на 1 -- 5 символов, то такие аккаунты считались фиктивными. Также если в характеристиках 2 и более аккаунтов встречается одинаковая часть (например, dtyekzneeplomo и tkbpfdtnfneeplomo).
    \item Проверка символов в имени пользователя, email и mailing\_address: представляют они осмысленный текст или произвольный набор символов. В случаях, когда почта была валидна, но состояла из рандомного набора, проверялись дата последнего входа в аккаунт и дата регистрации. Когда они были в диапазоне суток друг от друга, аккаунт считался фиктивным (например, аккаунт с username ramonjap, email bvbxzroi@dimail.xyz и mailing\_addressvljufcpn@dimail.xyz).
\end{enumerate}

После разметки было выяснено, что в данном датасете из 540 записей 204 (38\%) являются фиктивными, и 336 (62\%) -- настоящими. Примеры <<фейков>> и реальных аккаунтов рассмотрены в Приложении А.

\textbf{Тестирование}. Для тестирования работы системы был создан и размечен отдельный датасет, не пересекающийся с обучающим, содержащий 70 записей: 35 фиктивных и 35 настоящих аккаунтов. Он использовался для проведения экспериментов с алгоритмами и был разбит на несколько таблиц меньшего размера (путем удаления некоторых строк), в которых было различное соотношение фиктивных и реальных аккаунтов: 10\% и 90\%, 20\% и 80\%, 30\% и 70\%, 40\% и 60\%.
%\vspace{1.5em}
%\subsection{Выводы}
%\label{subsec:Itog}
%В данном разделе изучена предметная область курсовой работы (что такое Open Journal System, что является аккаунтом в данной системе), а также рассмотрены различные подходы к нахождению фиктивных аккаунтов, и какое влияние <<фейки>> оказывают. Можно сделать вывод, что из существующих решений, ни одно не затрагивало проблему нахождения фиктивных аккаунтов в Open Journal Systems. 

%Исходя из рассмотренных статей были выбраны три алгоритма для поиска аномалий и описаны метрики, с помощью которых будет оцениваться эффективность работы алгоритмов. 

%Был описан представленный датасет, с помощью которого производились эксперименты, представлены примеры размеченных записей.