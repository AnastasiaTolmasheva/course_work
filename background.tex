\newpage
\section{Анализ предметной области}
\label{sec:Background}

В разделе 1.1 представлен обзор предметной области проекта -- что такое Open Journal System и что представляет аккаунт в ней. Далее в рассмотрены аналогичные решения, их описание расположено в разделе 1.2. Методы, которые могут использоваться для поиска фиктивных аккаунтов описаны в разделе 1.3. Обзор набора данных для обучения, принципы разметки и примеры аккаунтов из датасета можно увидеть в разделе 1.4.

\vspace{1.5em}
\subsection{Предметная область}
\label{subsec:Variants}

Open Journal System (OJS) -- это программное обеспечение, которое позволяет публиковать статьи и организовать рабочий процесс издательства. На ее основе разработаны многие порталы, работают институты, научные центры и журналы в разных странах мира (интерфейс OPS переведeн более чем на 30 языков). Платформа обладает модульной структурой и имеет возможность подключения плагинов. 

OJS может быть рассмотрена как электронная библиотека: программа обеспечивает доступ к контенту, поиск по нему (автора, ключевые слова, названия статей, год выпуска и так далее). 

Аккаунт в Open Journal Systems представляет собой учетную запись пользователя, которая позволяет взаимодействовать с системой в качестве автора, рецензента, читателя или редактора в научных журналах, использующих OJS для управления процессом публикации.

Авторы могут создавать и отправлять свои научные статьи на публикацию в журнал. Их аккаунт позволяет им отслеживать статус статей, вносить изменения в данные и взаимодействовать с рецензентами.

Рецензенты имеют доступ к предоставленным им статьям. Их аккаунт дает им возможность отправлять свои оценки, взаимодействовать с редакцией и следить за обновлениями в процессе рецензирования.

Читатели могут создавать свои учетные записи для отслеживания интересующих статей, подписываться на уведомления о новых публикациях, а также участвовать в дискуссиях в комментариях к статьям.

Редакторы имеют полный доступ к управлению процессом публикации в журнале. Это включает в себя принятие и отклонение статей, управление рецензиями, управление составом редакционной коллегии и другие аспекты редакционной работы.

Администраторы имеют права доступа ко всем функциям системы и могут управлять пользователями, настройками, архивами и другими аспектами системы.

Поля, доступные в учетной записи пользователя OJS, могут немного различаться в зависимости от версии системы и настроек конкретного журнала, но учетные записи в обычно включают следующие базовые характеристики: имя пользователя, пароль, электронная почта, имя, фамилия, страна, аффилиация (принадлежность пользователя к организации, университету или другому учреждению), язык, ссылка, телефон, почтовый адрес.

\vspace{1.5em}
\subsection{Обзор аналогичных проектов}
\label{subsec:Variants}

Нахождение фиктивных аккаунтов в Open Journal System является темой данной работы. Для выбора наилучшего подхода к решению задач и достижения цели были рассмотрены некоторые статьи на тему выявления <<фейков>> и их влияния на аккаунты реальных людей. Далее представлены исследования, которые были использованы в ходе работы.

Авторы статьи~\cite{HassanAA23} раскрывают проблему поддельных страниц. Их количество растет вместе с увеличением числа активных пользователей. Поддельные профили на сайтах социальных сетей создают ненастоящие новости и распространяют нежелательные материалы, содержащие спам-ссылки. В этой статье приводится контролируемый алгоритм машинного обучения, называемый машиной опорных векторов, который используется вместе с методом случайного леса. Эту концепцию можно применить для идентификации большого количества учетных записей, которые невозможно проверить вручную. Данная модель сравнивается с другими методами идентификации, и результаты показывают, что предложенный авторами алгоритм работает с большей точностью. 

Статья~\cite{ElyusufiEK19} посвящена выявлению поддельных профилей в социальных сетях. Для их обнаружения было предложено множество алгоритмов и методов, и авторы этой работы оценивают точность использования дерева решений и наивного алгоритма Байеса для классификации профилей пользователей на поддельные и подлинные.

В работе~\cite{UppadaMVHS22} исследователи используют модель, которая определяет подлинность новостных статей, публикуемых в Twitter, на основе подлинности и предвзятости пользователей, которые взаимодействуют с этими статьями. Предлагаемая модель включает в себя идею оценки соотношения подписчиков, возраст аккаунта и т.д. Для анализа изображений предлагается использовать нейронную сеть (CredNN). Подход исследователей помогает обнаруживать поддельные изображения с точностью около 76\%.
    
В исследовании~\cite{GurajalaWHM15} проведен анализ 62 миллионов общедоступных профилей пользователей социальной сети Twitter, и разработана стратегия идентификации поддельных профилей. Используя алгоритм сопоставления шаблонов имен, анализ времени обновления твитов и даты создания профилей, были выявлены фиктивные учетные записи пользователей. 

В статье~\cite{abs-2308-05353} описывается новый алгоритм для обнаружения поддельных учетных записей в социальной сети. Авторы работы собирают некоторые из первых аналитических данных о том, как новые (поддельные и реальные) аккаунты пытаются завести друзей, ориентируясь на их первые запросы о дружбе после регистрации в социальной сети (Facebook). 

В работе~\cite{MohammadrezaeiS19} авторы представляют метод обнаружения, основанный на сходстве пользователей, с учетом их сетевых коммуникаций. На первом этапе измеряются такие параметры, как общие соседи, ребра графа общих соседей, косинус и коэффициент подобия Жаккарда~\cite{SantistebanT15}, которые вычисляются на основе матрицы смежности соответствующего графа социальной сети. На следующем шаге, чтобы уменьшить сложность данных, к каждой вычисленной матрице подобия применяется компонентный анализ для получения набора информативных признаков. Затем с помощью метода локтя выбирается набор высокоинформативных собственных векторов. Извлеченные функции используются для обучения алгоритма классификации. 

В статье~\cite{StolbovaGI21} представлено исследование поддельных аккаунтов в социальных сетях с использованием искусственной нейронной сети для их идентификации. Специально разработанное и внедренное приложение было использовано для выявления специфических особенностей поддельных аккаунтов и изучения принципов и причин их генерации. На основе изучения 500 реальных и 500 поддельных аккаунтов социальносй сети ВКонтакте был сделан ряд выводов об особенностях поддельных аккаунтов. Проведенное исследование позволило расширить список критериев идентификации поддельных аккаунтов набором шаблонов.

В статье~\cite{ChenW18} авторы нацеливаются на модель фиктивного аккаунта, который может не только автоматически публиковать сообщения или комментарии, но и рассылать рекламный спам или распространять ложную информацию. В этом исследовании был предложен метод обнаружения <<фейков>>. Он основан на шаблоне активности пользователя в Facebook с использованием машинного обучения, чтобы предсказать, контролируется ли учетная запись поддельным пользователем.

Работа~\cite{HsuKJ19} представляет результаты экспериментальной визуализации более 200 000 твитов из подтвержденных поддельных аккаунтов Twitter. Авторы анализируют учетные записи пользователей, изучая их имена пользователей, описания или биографии, твиты, их частоту и содержание. Исследователи обнаружили, что поддельные учетные записи узнаваемы благодаря политическим и религиозным убеждениям. Они присоединялись к популярным хэштегам в Twitter и публиковали твиты в острые моменты (например, во время дебатов).

Авторы статьи~\cite{FahmyAKE23} рассматривают влияние фиктивных аккаунтов на аккаунты людей. Цель работы -- представить новую модель распространения информации. Исследователи вводят два типа пользователей с разным уровнем <<зараженности>>: пользователи, <<инфицированные>> человеком, и пользователи, <<зараженные>> учетными записями ботов. Было измерено влияние поддельных аккаунтов на скорость распространения лжи среди записей людей. Результаты эксперимента показывали, что точность предложенной модели превосходит классическую при моделировании процесса распространения слухов. Был сделан вывод, что <<фейки>> ускоряют процесс распространения невподтвержденной информации, поскольку они воздействуют на многих людей за короткое время.

\vspace{1.5em}
\subsection{Обзор основных методов, используемых для поиска аномалий}
\label{subsec:Variants}
Методы, которые могут использоваться для поиска аномалий:

\textbf{Isolation Forest} (лес изоляции)~\cite{LiuTZ08} представляет собой алгоритм обнаружения аномалий, который строит ансамбль изолирующих деревьев решений. 

\textit{Дерево изоляции}. Пусть $T$ -- узел дерева изоляции. $T$ может быть либо внешним узлом без дочерних узлов, либо внутренним узлом с одним тестом и ровно двумя дочерними узлами ($T_l$, $T_r$). Тест состоит из атрибута $q$ и значения разделения $p$, такого, что тест $q$ < $p$ разделяет точки данных на $T_l$ и $T_r$. 

Дана выборка данных $X = \{x_1, \ldots, x_n\}$ из $n$ экземпляров из $d$-мерного распределения. Для построения дерева изоляции мы рекурсивно делим $X$, случайно выбирая атрибут $q$ и значение разделения $p$, пока дерево не достигнет предельной высоты, либо $|X| = 1$, либо все данные в $X$ будут иметь одинаковые значения. Дерево изоляции -- это правильное бинарное дерево, где каждый узел в дереве имеет ровно ноль или два дочерних узла.

Одним из способов обнаружения аномалий с помощью дерева изоляции является сортировка точек данных по их длинам пути или оценкам аномалий; и аномалии -- это точки, которые занимают верхние позиции в списке. Длина пути $h(x)$ точки $x$ измеряется количеством рёбер, которые $x$ проходит в дереве изоляции от корневого узла до завершения обхода во внешнем узле.

Работа алгоритма леса изоляции:
\vspace{-1.5em}
\begin{enumerate}[itemsep=0pt, topsep=1.5em]
    \item Случайное разбиение. Дерево случайным образом выбирает атрибут и значение разделения данных. Это создает разделение, которое помогает выделить аномалии.
    \item Рекурсивная изоляция. Дерево повторяет процесс, разделяя данные на более мелкие группы. Цель состоит в том, чтобы изолировать аномалии от обычных данных.
    \item Идентификация аномалий. Аномалии идентифицируются как точки данных, для выделения которых требуется меньшее количество разбиений.
    \item Определение изолирующего пути. Определяется количество разбиений, необходимых для изоляции точки данных, служит мерой её аномальности.
    \item Ансамбль деревьев. Алгоритм создает несколько деревьев изоляции, независимых друг от друга, образующих ансамбль, который коллективно оценивает аномалии.
    \item Расчет оценки различий. Вычисляется среднее расстояние разделения между всеми деревьями для каждой точки данных, что дает оценку аномалии.
    \item Классификация. Используются предопределенные пороги для отличения нормальных и аномальных точек данных. Объекты с высокими оценками помечаются как аномалии.
\end{enumerate}
\vspace{-1.5em}

\textbf{Hierarchical clustering} (иерархическая кластеризация) -- это алгоритм группировки данных, который строит иерархию кластеров. Существует два основных подхода: агломеративный и дивизивный.

\textit{Агломеративная кластеризация}. Каждая точка рассматривается как отдельный кластер. На каждом шаге ближайшие кластеры объединяются в новый кластер (на основании расстояния между кластерами или другими мерами сходства). Повторяется до тех пор, пока все точки не объединятся в один кластер.
    
\textit{Дивизивная кластеризация}. Вся выборка рассматривается как один кластер. На каждом шаге один из кластеров разбивается на более мелкие кластеры (на основании мер несходства между подгруппами). Процесс повторяется до тех пор, пока каждая точка не станет отдельным кластером.
    
Результат иерархической кластеризации представляет собой дерево, называемое дендрограммой. Дендрограмма отображает последовательное объединение или разделение кластеров в зависимости от расстояний или мер сходства.

В данной работе рассматривался алгоритм агломеративной кластеризации~\cite{Banfield1993ModelbasedGA}. Можно выделить несколько методов вычисления связи.

Метод одиночной связи (single linkage): расстояние между кластерами равно минимальному расстоянию между точками из разных кластеров.
\[ d_{\min}(C_i, C_j) = \min_{x \in C_i, y \in C_j} \rho(x, y) \]

Метод полной связи (complete linkage): расстояние между кластерами равно максимальному расстоянию между точками из разных кластеров.
\[ d_{\max}(C_i, C_j) = \max_{x \in C_i, y \in C_j} \rho(x, y) \]

Метод средней связи (average linkage): расстояние между кластерами равно среднему расстоянию между всеми парами точек из разных кластеров.
\[ d_{\text{avg}}(C_i, C_j) = \frac{1}{n_i n_j} \sum_{x \in C_i} \sum_{y \in C_j} \rho(x, y) \]

Метод Уорда (Ward's linkage): расстояние между кластерами равно приросту суммы квадратов расстояний от точек до центроидов кластеров при объединении этих кластеров. Этот метод стремится минимизировать внутрикластерную дисперсию.
\[ d_{\text{ward}}(C_i, C_j) = \frac{n_i n_j}{n_i + n_j} \rho^2(\bar{x}_i, \bar{x}_j) \]


\textbf{DBSCAN} (Density-Based Spatial Clustering of Applications with Noise) ~\cite{EsterKSX96} -- это алгоритм кластеризации, который определяет кластеры на основе плотности данных в пространстве. Он может обнаруживать кластеры произвольной формы и выделять точки, не принадлежащие ни одному кластеру (шум).
    
Для нахождения кластера DBSCAN начинает с произвольной точки $p$ и извлекает все точки, достижимые по плотности из $p$ относительно $Eps$ и $MinPts$. Если $p$ является ядром кластера, этот процесс дает кластер относительно $Eps$ и $MinPts$. Если $p$ является граничной точкой, и нет точек, достижимых по плотности, и DBSCAN переходит к следующему объекту в базе данных.

Для алгоритма DBSCAN необходимо указывать параметры $Eps$ и $MinPts$.

Параметр $Eps$ определяет окрестности вокруг точек данных: если расстояние между двумя точками меньше или равно $Eps$, то они считаются соседними. Если значение $Eps$ выбрано слишком маленьким, то большая часть данных будет считаться шумом. Если же выбрано очень большое значение $Eps$, то кластеры объединятся, и большинство объектов окажется в одних и тех же кластерах.

Параметр $MinPts$ представляет собой минимальное количество соседей (точек данных) в радиусе $Eps$. Чем больше набор данных, тем большее значение $minPts$ следует выбрать.

\textbf{Метрики}

Для оценки качества работы алгоритма будут использоваться метрики accuracy (аккуратность), precision (точность) и recall (полнота), F-measure (F-мера). Первая показывает долю верно классифицированных объектов, вторая -- долю объектов, которые модель классифицировала как положительные, и которые действительно являются положительными, а третья -- долю объектов положительного класса, которые модель определила правильно, четвертая -- это комбинированная метрика, объединяющая точность и полноту в единственное число. 

Данные метрики можно вычислить по следующим формулам:


$$
accuracy = \frac{TP+TN}{TP+TN+FP+FN}
$$

$$
precision = \frac{TP}{TP+FP}
$$

$$
recall = \frac{TP+TN}{TP+FN}
$$

$$
F\text{-}measure = 2\cdot \frac{precision \cdot recall}{precision+recall}
$$

\vspace{1.5em}
Термины TP, TN, FP, FN используются в контексте матрицы ошибок (таблица ~\ref{tabular:tableMistakes}), которая является инструментом для оценки производительности моделей.

\begin{table}[H]
    \onehalfspacing \caption{Матрица ошибок}
    \medskip
    \begin{tabular}{c|cc}
        & \text{Positive} & \text{Negative} \\
        \hline
        \text{True} & \text{True Positives} & \text{True Negatives} \\
        \text{False} & \text{False Positives} & \text{False Negatives} \\
    \end{tabular}
    \label{tabular:tableMistakes}
\end{table}

TP (True Positives) -- количество верно предсказанных положительных примеров. Это случаи, когда модель правильно предсказала, что объект принадлежит к положительному классу. В данной работе это будут те аккаунты, которые являются фиктивными, и модель классифицировала их как аномальные.

TN (True Negatives) -- количество верно предсказанных отрицательных примеров. Это случаи, когда модель правильно предсказала, что объект принадлежит к отрицательному классу. В данной работе это будут те аккаунты, которые являются реальными, и модель не классифицировала их как аномальные.

FP (False Positives) -- количество ложно положительных примеров. Это случаи, когда модель ошибочно предсказала, что объект принадлежит к положительному классу, хотя на самом деле он принадлежит отрицательному классу. В данной работе это будут те аккаунты, которые являются реальными, но модель классифицировала их как аномальные.

FN (False Negatives) -- количество ложно отрицательных примеров. Это случаи, когда модель ошибочно предсказала, что объект принадлежит отрицательному классу, хотя на самом деле он принадлежит положительному классу. В данной работе это будут те аккаунты, которые являются фиктивными, но модель не классифицировала их как аномальные.

\vspace{1.5em}
\subsection{Набор данных для обучения}
\label{subsec:Dataset}

Для обучения модели был применен датасет с реальными данными аккаунов, который имеет следующие столбцы: user\_id, username, password, email, url, phone, mailing\_address, billing\_address, country, locales, date\_last\_email, date\_registered, date\_validated, date\_last\_login, must\_change\_password, auth\_id, auth\_str, disabled, disabled\_reason, inline\_help, gossip. 

Была произведена его разметка с добавлением колонки fake, в которой 1 показывает, что аккаунт фиктивный, а 0 -- настоящий. 
Разметка происходила по следующим признакам:
\vspace{-1.5em}
\begin{enumerate}[itemsep=0pt, topsep=1.5em]
    \item Проверка email на валидность (просмотр синтаксиса и возможности доставки на домен). Если почта не валидна, то аккаунт считается фиктивным (например, аккаунт с id 4237 и email admin@cr6ptobrowser.site);
    \item Проверка mailing\_address на валидность (просмотр синтаксиса и возможности доставки на домен). Если почта не валидна, то аккаунт считается фиктивным (например, аккаунт с id 10666 и mailing\_address trinapv1@sora81.sorataki.in.net);
    \item Проверка работы ссылки, указанной в аккаунте. Если ссылка не работала, то аккаунт считается фиктивным (например, аккаунт с ссылкой http://viaforsl.com);
    \item Проверка содержимого сайта, указанного в ссылке аккаунта. Если там находится что-либо, не связанное с научными публикациями, аккаунт считается фиктивным (например, аккаунт с id 3895 ссылкой на казино: https://vsem-zabor.ru);
    \item Просмотр ближайших строк сверху и снизу по списку -- если имена пользователей, email или billing\_addres различаются на 1 -- 5 символов, то такие аккаунты считаются фиктивными. Также если в характеристиках 2 и более аккаунтов встречается одинаковая часть (например, dtyekzneeplomo и tkbpfdtnfneeplomo, которые идут друг за другом, считаются фиктивными);
    \item Проверка символов в имени пользователя, email и mailing\_address: представляют они осмысленный текст или произвольный набор. В случаях, когда почта была валидна, но состояла из рандомного набора символов, проверялись дата последнего захода в аккаунт и дата регистрации. В случаях, когда они были в диапазоне суток друг от друга, аккаунт считается фиктивным (например, аккаунт с username ramonjap, email bvbxzroi@dimail.xyz и mailing\_addressvljufcpn@dimail.xyz).
\end{enumerate}
\vspace{-1.5em}

После разметки было выяснено, что в данном датасете из 540 записей 204 (38\%) являются фиктивными, и 336 (62\%) -- настоящими. Примеры <<фейков>> и реальных аккаунтов рассмотрены в Приложении А.

\vspace{1.5em}
\subsection{Заключение}
\label{subsec:Itog}
В данном разделе изучена предметная область курсовой работы (что такое Open Journal System, что является аккаунтом в данной системе), а также рассмотрены различные подходы к нахождению фиктивных аккаунтов, и какое влияние <<фейки>> оказывают. Можно сделать вывод, что из существующих решений, ни одно не затрагивало проблему нахождения фиктивных аккаунтов в Open Journal Systems. 

Исходя из рассмотренных статей были выбраны три алгоритма для поиска аномалий и описаны метрики, с помощью которых будет оцениваться эффективность работы алгоритмов. 

Был описан представленный датасет, с помощью которого производились эксперименты, представлены примеры размеченных записей.